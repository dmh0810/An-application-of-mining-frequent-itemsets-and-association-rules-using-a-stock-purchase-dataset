#################################################################
########### R-Script Hausarbeit: Warenkorbanalyse ###############
#################################################################

#Veranstaltung: Empirische Kundendatenanalyse: Eine praxisorientierte Einführung
#Studentin: Minh Huong Dao
#Matrikelnummer: 6311120

setwd("D:/Uni Goethe Wiwi/Wintersemester 2019 2020/Empirische Kundendatenanalyse/Hausarbeit")

library(arules)
library(arulesViz)
library(readstata13)

#### Prepare data 
# Original data structure: each row is one single item
wp2019<- read.dta13("wp.dta")
wp2019[1:10,]

# Data collapse in transaction data
library(plyr)
library(dplyr)
wp2019trx <- ddply(wp2019,c("lfd_nr"),  function(df1)paste(df1$wp_bez,  collapse = "#"))

# remove unnecessary column
wp2019trx$lfd_nr <- NULL

# Write the transaction data in an excel file 
write.table(wp2019trx,"D:/Uni Goethe Wiwi/Wintersemester 2019 2020/Empirische Kundendatenanalyse/Hausarbeit/wpkaeufe2019.csv", quote=FALSE, row.names = FALSE,sep="#")

# Load transaction data
wp_basket <- read.transactions(file="wpkaeufe2019.csv",sep="#",format="basket", quote="", skip=1)

# Transaction data structure
inspect(wp_basket[1:10])

# Overview of the data structure
summary(wp_basket)

# Histogram of the transactions length
hist(size(wp_basket), main = "Transaction lengths", xlim = c(1,15),ylim = c(0,60000))

# Purchase frequency of top 20 securities
itemFrequencyPlot(wp_basket,topN = 20, cex.names = 0.5)

# Item frequency of frequent items (68 items that have support over 0.01)
itemFrequencyPlot(wp_basket, support = 0.01, cex.names = 0.5)

# Examine closer the itemmatrix data structure
itemMatrix <- as(wp_basket, "itemMatrix")

# get first 5 rows and 5 columns of the itemMatrix as matrix
as(itemMatrix[1:5,1:5], "matrix")

##### Mine important association rules
# mining rules for different support threshold values
rules_0.005 <- apriori(wp_basket, parameter = list(support = 0.005, confidence = 0.6, maxlen=7))
plot(rules_0.005, measure = "support", shading = "lift")

### Chosen parameters: support=0.01, confidence=0.6, maxlen=7
### Mine frequent item sets
frequent_itemsets <- apriori(wp_basket, parameter = list(target="frequent itemsets", support = 0.01, confidence = 0.6, maxlen = 7))

### Mine rules at support = 0.01, confidence = 0.6, maxlen = 7                                    
rules <- apriori(wp_basket, parameter = list(support = 0.01, confidence = 0.6, maxlen=7))
summary(rules)
plot(rules, measure = "support", shading = "lift")

#Execution time of rules mining 
time_normal <- system.time(itemPop <- apriori(wp_basket, parameter = list(support = 0.01, confidence = 0.6, maxlen=7)))

# Original Rules inspect, ordered by lift 
inspect(sort(rules, by = "lift")[1:10])

# remove redundant rules 
redundant_rules <- rules[is.redundant(rules)]
inspect(sort(rules[!is.redundant(rules)], by = "lift")[1:10])
inspect(sort(redundant_rules, by = "lift")[1:10])
rules_neu <- rules[!is.redundant(rules)]
summary(rules_neu)

#Sort by lift
inspect(sort(rules_neu, by = "lift")[1:10])
# Sort by support
inspect(sort(rules_neu, by = "support")[1:10])
# Sort by confidence 
inspect(sort(rules_neu, by = "confidence")[1:10])

#### Build and examine subsets of rules 
#Subset of rules with high lift
rules_high_lift <- subset(rules_neu, lift > 40)
summary(rules_high_lift)
inspect(sort(rules_high_lift, by = "lift")[1:2])

#Subset of rules with high support
rules_high_supp <- subset(rules_neu, support >= 0.1)
summary(rules_high_supp)
inspect(sort(rules_high_supp, by = "support"))

#Subset of rules with high confidence
rules_high_conf <- subset(rules_neu, confidence > 0.99)
summary(rules_high_conf)
inspect(sort(rules_high_conf, by = "confidence")[1:2])

#Subset of rules with iShsIV in the RHS
rules_iShsIV_r <- subset(rules_neu, rhs %in% "iShsIV-Edge MSCI USA V.F.U.ETF Registered Shares o.N.")
inspect(head(rules_iShsIV_r, n = 1, by = "support"))
summary(rules_iShsIV_r)

#Subset rules with iShsIV in the LHS 
rules_iShsIV_l <- subset(rules_neu, lhs %in% "iShsIV-Edge MSCI USA V.F.U.ETF Registered Shares o.N.")
inspect(head(rules_iShsIV_l, n = 1, by = "support"))
summary(rules_iShsIV_l)


#### Selective rules generation: Rules induction (decoupling rule generation from frequent itemset mining to gain more flexibility)
#### use any methods to define a set of "interesting" itemsets and then generate rules from only these itemsets

# Define closed item sets that have support = 0.01, confidence = 0.6, maxlen=7
closed_is <- apriori(wp_basket, parameter = list(target="closed", support = 0.01, confidence = 0.6, maxlen = 7))
# induce all rules that can be generated by the given item sets
# use ruleInduction to produce all closed association rules: 
closed_rules <- ruleInduction(closed_is, wp_basket, control = list(verbose = TRUE))

summary(closed_rules)

# Time mining 
time_closed <- system.time(ruleInduction(closed_is, wp_basket, control = list(verbose = TRUE)))

inspect(sort(closed_rules, by = "lift")[1:5])

### Sampling 
# Sample size using formula of Zaki et al. for support = 0.01, error rate = 10% and confidence level = 95%
supp <- 0.01
errorRate <- 0.1
alpha <- 0.05
n <- -2*log(alpha)/(supp*errorRate^2)

# Create a sample of the database
wp_basket_sample <- sample(wp_basket, n, replace = TRUE)

# Compare the item frequency of the population vs the sample 
itemFrequencyPlot(wp_basket_sample, population = wp_basket, support = supp, cex.names = 0.5)

# Mine frequent item sets on the population and sample
itemPop <- apriori(wp_basket, parameter = list(target = "frequent itemsets", support = supp, confidence = 0.6, maxlen = 7), control = list(verbose = FALSE))

itemSample <- apriori(wp_basket_sample, parameter = list(target = "frequent itemsets", support = supp, confidence = 0.6, maxlen = 7), control = list(verbose = FALSE))

# Mining time
timePop <- system.time(itemPop <- apriori(wp_basket, parameter = list(target = "frequent itemsets", support = supp, confidence = 0.6, maxlen = 7), control = list(verbose = FALSE)))

timeSample <- system.time(itemSample <- apriori(wp_basket_sample, parameter = list(target = "frequent itemsets", support = supp, confidence = 0.6, maxlen = 7), control = list(verbose = FALSE)))

timePop[1]/timeSample[1]

# Chekc if the sample set contains the same item sets as in the original set 
match <- match(itemPop, itemSample, nomatch = 0)
sum(match > 0)/length(itemPop) #Result: match = 1, all frequent itemsets mined in the population
#can be found in the sample 
